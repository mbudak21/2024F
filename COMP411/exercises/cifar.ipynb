{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\murat\\.conda\\envs\\edf\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# download CIFAR dataset\n",
    "NUM_TRAIN = 40000\n",
    "\n",
    "transform = v2.Compose([v2.ToTensor(), v2.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "cifar_train = dset.CIFAR10('./datasets', train=True, download=True, transform=transform)\n",
    "cifar_val = dset.CIFAR10('./datasets', train=False, download=True, transform=transform)\n",
    "loader_train = DataLoader(cifar_train, batch_size=64, sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "loader_val = DataLoader(cifar_val, batch_size=64)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 64 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer, reg, w_reg):\n",
    "    # reg defines the type of regularization, either 'l1' or 'l2' or None\n",
    "    # w_reg is the regularization weight\n",
    "    model.train()\n",
    "    for x, y in dataloader:\n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        pred = model(x)\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "def eval_loop(dataloader, model, loss_fn, reg=None, w_reg=None):\n",
    "    # reg defines the type of regularization, either 'l1' or 'l2' or None\n",
    "    # w_reg is the regularization weight\n",
    "    # modify this function the same as the train_loop\n",
    "    model.eval()\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x = x.to(DEVICE)\n",
    "            y = y.to(DEVICE)\n",
    "            pred = model(x)\n",
    "            loss = loss_fn(pred, y)\n",
    "            total_loss += loss.item()\n",
    "            num_correct += (pred.argmax(1) == y).sum().item()\n",
    "            num_samples += pred.shape[0]\n",
    "    \n",
    "    acc = 100*(num_correct / num_samples)\n",
    "    total_loss /= len(dataloader)\n",
    "    return acc, total_loss \n",
    "\n",
    "\n",
    "def run(loader_train, loader_val, model, loss_fn, optimizer, num_epochs=1, reg=None, w_reg=None):\n",
    "    torch.manual_seed(0)\n",
    "    np.random.seed(0)\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    for i in range(num_epochs):\n",
    "        train_loop(loader_train, model, loss_fn, optimizer, reg, w_reg)\n",
    "        train_acc, train_loss = eval_loop(loader_train, model, loss_fn, reg, w_reg)\n",
    "        val_acc, val_loss = eval_loop(loader_val, model, loss_fn, reg, w_reg)\n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        print(f'Epoch {i+1}/{num_epochs}, Train Acc: {train_acc:.4f}%, Val Acc: {val_acc:.4f}%')\n",
    "    print('-'*50)\n",
    "    return train_accs, val_accs, train_losses, val_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "num_epochs = 1\n",
    "lr = 1e-3\n",
    "weight_decay = 0\n",
    "model = CustomCNN().to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Train Acc: 56.4500%, Val Acc: 55.5900%\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "train_accs, val_accs, train_losses, val_losses = run(loader_train, loader_val, model, loss_fn, optimizer, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorboard\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting absl-py>=0.4 (from tensorboard)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard)\n",
      "  Downloading grpcio-1.68.1-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\murat\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard) (2.1.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\murat\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard) (24.1)\n",
      "Collecting protobuf!=4.24.0,>=3.19.6 (from tensorboard)\n",
      "  Downloading protobuf-5.29.0-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\murat\\.conda\\envs\\edf\\lib\\site-packages (from tensorboard) (72.1.0)\n",
      "Requirement already satisfied: six>1.9 in c:\\users\\murat\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard) (1.16.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\murat\\.conda\\envs\\edf\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\n",
      "Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/5.5 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 1.6/5.5 MB 5.2 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 2.4/5.5 MB 4.6 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 2.9/5.5 MB 4.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 3.4/5.5 MB 3.7 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 3.7/5.5 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 3.9/5.5 MB 3.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 4.5/5.5 MB 2.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 4.5/5.5 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 4.7/5.5 MB 2.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.0/5.5 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.0/5.5 MB 2.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 5.2/5.5 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 2.0 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading grpcio-1.68.1-cp312-cp312-win_amd64.whl (4.4 MB)\n",
      "   ---------------------------------------- 0.0/4.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/4.4 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.3/4.4 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.3/4.4 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.5/4.4 MB 699.0 kB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 0.5/4.4 MB 699.0 kB/s eta 0:00:06\n",
      "   ------- -------------------------------- 0.8/4.4 MB 713.3 kB/s eta 0:00:06\n",
      "   --------- ------------------------------ 1.0/4.4 MB 774.0 kB/s eta 0:00:05\n",
      "   --------- ------------------------------ 1.0/4.4 MB 774.0 kB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 1.3/4.4 MB 771.0 kB/s eta 0:00:04\n",
      "   -------------- ------------------------- 1.6/4.4 MB 798.7 kB/s eta 0:00:04\n",
      "   -------------- ------------------------- 1.6/4.4 MB 798.7 kB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 1.8/4.4 MB 798.8 kB/s eta 0:00:04\n",
      "   ------------------- -------------------- 2.1/4.4 MB 809.8 kB/s eta 0:00:03\n",
      "   --------------------- ------------------ 2.4/4.4 MB 828.3 kB/s eta 0:00:03\n",
      "   --------------------- ------------------ 2.4/4.4 MB 828.3 kB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 2.6/4.4 MB 843.5 kB/s eta 0:00:03\n",
      "   -------------------------- ------------- 2.9/4.4 MB 864.6 kB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 3.1/4.4 MB 882.9 kB/s eta 0:00:02\n",
      "   ------------------------------- -------- 3.4/4.4 MB 906.8 kB/s eta 0:00:02\n",
      "   --------------------------------- ------ 3.7/4.4 MB 920.1 kB/s eta 0:00:01\n",
      "   --------------------------------- ------ 3.7/4.4 MB 920.1 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 3.9/4.4 MB 910.2 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 4.2/4.4 MB 895.5 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 4.2/4.4 MB 895.5 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.4/4.4 MB 892.5 kB/s eta 0:00:00\n",
      "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading protobuf-5.29.0-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Installing collected packages: werkzeug, tensorboard-data-server, protobuf, markdown, grpcio, absl-py, tensorboard\n",
      "Successfully installed absl-py-2.1.0 grpcio-1.68.1 markdown-3.7 protobuf-5.29.0 tensorboard-2.18.0 tensorboard-data-server-0.7.2 werkzeug-3.1.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "model = CustomCNN()\n",
    "writer = SummaryWriter(\"runs/CustomCNN\")\n",
    "dummy_input = torch.randn(1, 3, 32, 32)  # Example input size\n",
    "writer.add_graph(model, dummy_input)\n",
    "writer.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
